{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow\n",
    "# TensorFlow vs. PyTorch: A Tale of Two Deep Learning Giants 🧠🔍\n",
    "\n",
    "---\n",
    "\n",
    "# 1. Introduction: Tensor Math with a Sprinkle of Keras Magic  \n",
    "At their core, **TensorFlow** and **PyTorch** are frameworks designed to perform *tensor algebra*—the lifeblood of deep learning.  \n",
    "Tensors are fancy, multidimensional arrays that enable efficient data manipulation on GPUs.\n",
    "\n",
    "- **TensorFlow**: Known for its robust **Keras** API, a high-level library for building models easily.  \n",
    "  Think of Keras as LEGO bricks that make TensorFlow approachable for beginners and scalable for production.\n",
    "  \n",
    "- **PyTorch**: Offers a more Pythonic and intuitive interface, loved by researchers for its dynamic computation graph.  \n",
    "  It’s like the Swiss Army knife for prototyping!\n",
    "\n",
    "---\n",
    "\n",
    "# 2. Attributes of Tensors: The Building Blocks of Deep Learning  \n",
    "Tensors have several key attributes:  \n",
    "\n",
    "- **Rank**: The number of dimensions a tensor has.  \n",
    "  - Example: A scalar (single number) has rank 0, a vector has rank 1, and a matrix has rank 2.  \n",
    "\n",
    "- **Order**: Synonymous with rank; another term for it.  \n",
    "\n",
    "- **Shape**: The size of each dimension in the tensor.  \n",
    "  For instance, a tensor with shape `(3, 4, 5)` has 3 dimensions.  \n",
    "\n",
    "- **Datatype**: Tensors can store data of different types like `float32`, `int64`, etc.  \n",
    "\n",
    "> **Fun Fact**: In PyTorch, `tensor.dtype` is like the recipe for your tensor, while `tensor.shape` tells you its serving size. 🍽️\n",
    "\n",
    "---\n",
    "\n",
    "# 3. Methods/Operations on Tensors: Math on Steroids  \n",
    "Both frameworks excel at tensor operations. Here’s a taste of what you can do:  \n",
    "\n",
    "- **Matrix Multiplication**:  \n",
    "  - TensorFlow: `tf.matmul(a, b)`  \n",
    "  - PyTorch: `torch.mm(a, b)`  \n",
    "\n",
    "- **Element-wise Operations**:  \n",
    "  Operations like addition, subtraction, etc., applied element by element.  \n",
    "\n",
    "- **Gradients and Autograd**:  \n",
    "  Both frameworks support automatic differentiation.  \n",
    "  - TensorFlow: Handles gradients with `tf.GradientTape()`.  \n",
    "  - PyTorch: Offers `torch.autograd` with dynamic computation graphs, perfect for experimentation.  \n",
    "\n",
    "> PyTorch’s dynamic graph lets you modify the graph on the fly, while Tenso\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attributes & Data\n",
    "Tensors have shapes. Some vocabulary:\n",
    "\n",
    "Shape: The length (number of elements) of each of the axes of a tensor.\n",
    "\n",
    "Rank: Number of tensor axes. A scalar has rank 0, a vector has rank 1, a matrix is rank 2.\n",
    "\n",
    "Axis or Dimension: A particular dimension of a tensor.\n",
    "\n",
    "Size: The total number of items in the tensor, the product of the shape vector's elements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant([[1., 2., 3.],\n",
    "                 [4., 5., 6.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x)\n",
    "print(x.shape)\n",
    "print(x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.rank(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "5 * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x @ tf.transpose(x) #Matmul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.matmul(x, tf.transpose(x)) #Matmul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.tensordot(x, x, axes = (1,1)) #Tensor dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.concat([x, x, x], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.nn.softmax(x, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reduce_sum(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.convert_to_tensor([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if tf.config.list_physical_devices('GPU'):\n",
    "  print(\"TensorFlow **IS** using the GPU\")\n",
    "else:\n",
    "  print(\"TensorFlow **IS NOT** using the GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ragged Tensors\n",
    "A tensor with variable numbers of elements along some axis is called \"ragged\". Use tf.ragged.RaggedTensor for ragged data.\n",
    "\n",
    "For example, This cannot be represented as a regular tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ragged_list = [\n",
    "    [0, 1, 2, 3],\n",
    "    [4, 5],\n",
    "    [6, 7, 8],\n",
    "    [9]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "  tensor = tf.constant(ragged_list)\n",
    "except Exception as e:\n",
    "  print(f\"{type(e).__name__}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ragged_tensor = tf.ragged.constant(ragged_list)\n",
    "print(ragged_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "String tensors\n",
    "tf.string is a dtype, which is to say you can represent data as strings (variable-length byte arrays) in tensors.\n",
    "\n",
    "The strings are atomic and cannot be indexed the way Python strings are. The length of the string is not one of the axes of the tensor. See tf.strings for functions to manipulate them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensors can be strings, too here is a scalar string.\n",
    "scalar_string_tensor = tf.constant(\"Gray wolf\")\n",
    "print(scalar_string_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sparse tensors:\n",
    "Sometimes, your data is sparse, like a very wide embedding space. TensorFlow supports tf.sparse.SparseTensor and related operations to store sparse data efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sparse tensors store values by index in a memory-efficient manner\n",
    "sparse_tensor = tf.sparse.SparseTensor(indices=[[0, 0], [1, 2]],\n",
    "                                       values=[1, 2],\n",
    "                                       dense_shape=[3, 4])\n",
    "print(sparse_tensor, \"\\n\")\n",
    "\n",
    "# You can convert sparse tensors to dense\n",
    "print(tf.sparse.to_dense(sparse_tensor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operations\n",
    "Normal tf.Tensor objects are immutable. To store model weights (or other mutable state) in TensorFlow use a tf.Variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = tf.Variable(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var.assign(var+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.Variable(2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "  y = x**2 + 2*x - 5\n",
    "  return y\n",
    "f(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "  y = f(x)\n",
    "\n",
    "g_x = tape.gradient(y, x)  # g(x) = dy/dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def my_func(x):\n",
    "  print('Tracing.\\n')\n",
    "  return tf.reduce_sum(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first time you run the tf.function, although it executes in Python, it captures a complete, optimized graph representing the TensorFlow computations done within the function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common pre-existing layers\n",
    "In the tf.keras.layers package, layers are objects. To construct a layer,\n",
    "simply construct the object. Most layers take as a first argument the number\n",
    "of output dimensions / channels.\n",
    "layer = tf.keras.layers.Dense(100)\n",
    "The number of input dimensions is often unnecessary, as it can be inferred\n",
    "the first time the layer is used, but it can be provided if you want to\n",
    "specify it manually, which is useful in some complex models.\n",
    "layer = tf.keras.layers.Dense(10, input_shape=(None, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom layers\n",
    "The best way to implement your own layer is extending the tf.keras.Layer class and implementing:\n",
    "\n",
    "* __init__ , where you can do all input-independent initialization\n",
    "* build, where you know the shapes of the input tensors and can do the rest of the initialization\n",
    "* call, where you do the forward computation\n",
    "\n",
    "Note that you don't have to wait until build is called to create your variables, you can also create them in __init__. However, the advantage of creating them in build is that it enables late variable creation based on the shape of the inputs the layer will operate on. On the other hand, creating variables in __init__ would mean that shapes required to create the variables will need to be explicitly specified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models: Composing layers\n",
    "Many interesting layer-like things in machine learning models are implemented by composing existing layers. For example, each residual block in a resnet is a composition of convolutions, batch normalizations, and a shortcut. Layers can be nested inside other layers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CORE: Multiple linear regression\n",
    "This quickstart tutorial demonstrates how you can use the TensorFlow Core low-level APIs to build and train a multiple linear regression model that predicts fuel efficiency. It uses the Auto MPG dataset which contains fuel efficiency data for late-1970s and early 1980s automobiles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and preprocess datasets\n",
    "Usage of tensorflow specific named container class tf.Module for abstraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data'\n",
    "column_names = ['MPG', 'Cylinders', 'Displacement', 'Horsepower', 'Weight',\n",
    "                'Acceleration', 'Model Year', 'Origin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(url, names=column_names,\n",
    "                       na_values='?', \n",
    "                       comment='\\t',\n",
    "                          sep=' ', \n",
    "                          skipinitialspace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling na values via dropping records with na\n",
    "dataset = dataset.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To do or think of quicker ways of applying imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_tf = tf.convert_to_tensor(dataset, dtype=tf.float32)\n",
    "dataset.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_shuffled = tf.random.shuffle(dataset_tf, seed=22)\n",
    "train_data, test_data = dataset_shuffled[100:], dataset_shuffled[:100]\n",
    "x_train, y_train = train_data[:, 1:], train_data[:, 0]\n",
    "x_test, y_test = test_data[:, 1:], test_data[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot_origin(x):\n",
    "  \"Encoding label encoded origins which will be problematic to be used as numeric data features\"\n",
    "  origin = tf.cast(x[:, -1], tf.int32)\n",
    "  # Use `origin - 1` to account for 1-indexed feature\n",
    "  origin_oh = tf.one_hot(origin - 1, 3)\n",
    "  x_ohe = tf.concat([x[:, :-1], origin_oh], axis = 1)\n",
    "  return x_ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_ohe, x_test_ohe = onehot_origin(x_train), onehot_origin(x_test)\n",
    "x_train_ohe.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normalize(tf.Module):\n",
    "  def __init__(self, x):\n",
    "    # Initialize the mean and standard deviation for normalization\n",
    "    self.mean = tf.math.reduce_mean(x, axis=0)\n",
    "    self.std = tf.math.reduce_std(x, axis=0)\n",
    "\n",
    "  def norm(self, x):\n",
    "    # Normalize the input\n",
    "\n",
    "    return (x - self.mean)/self.std\n",
    "\n",
    "  def unnorm(self, x):\n",
    "    # Unnormalize the input\n",
    "    return (x * self.std) + self.mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_x = Normalize(x_train_ohe)\n",
    "norm_y = Normalize(y_train)\n",
    "x_train_norm, y_train_norm = norm_x.norm(x_train_ohe), norm_y.norm(y_train)\n",
    "x_test_norm, y_test_norm = norm_x.norm(x_test_ohe), norm_y.norm(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model (Abstracted as sequential and layers in keras)\n",
    "Again using tf.Module for abstraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression(tf.Module):\n",
    "\n",
    "  def __init__(self):\n",
    "    self.built = False\n",
    "\n",
    "  @tf.function\n",
    "  def __call__(self, x):\n",
    "    # Initialize the model parameters on the first call\n",
    "    if not self.built:\n",
    "      # Randomly generate the weight vector and bias term\n",
    "      rand_w = tf.random.uniform(shape=[x.shape[-1], 1])\n",
    "      rand_b = tf.random.uniform(shape=[])\n",
    "      self.w = tf.Variable(rand_w)\n",
    "      self.b = tf.Variable(rand_b)\n",
    "      self.built = True\n",
    "    y = tf.add(tf.matmul(x, self.w), self.b)\n",
    "    return tf.squeeze(y, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg = LinearRegression()\n",
    "prediction = lin_reg(x_train_norm[:1])\n",
    "prediction_unnorm = norm_y.unnorm(prediction)\n",
    "prediction_unnorm.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining loss function (Abstracted as compile in keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_loss(y_pred, y):\n",
    "  return tf.reduce_mean(tf.square(y_pred - y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and evaluation functions (Abstracted as fit and predict functions in keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Minibatch gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train_norm, y_train_norm))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=x_train.shape[0]).batch(batch_size)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test_norm, y_test_norm))\n",
    "test_dataset = test_dataset.shuffle(buffer_size=x_test.shape[0]).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set training parameters\n",
    "epochs = 100\n",
    "learning_rate = 0.01\n",
    "train_losses, test_losses = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format training loop\n",
    "for epoch in range(epochs):\n",
    "  batch_losses_train, batch_losses_test = [], []\n",
    "\n",
    "  # Iterate through the training data\n",
    "  for x_batch, y_batch in train_dataset:\n",
    "    with tf.GradientTape() as tape:\n",
    "      y_pred_batch = lin_reg(x_batch)\n",
    "      batch_loss = mse_loss(y_pred_batch, y_batch)\n",
    "    # Update parameters with respect to the gradient calculations\n",
    "    grads = tape.gradient(batch_loss, lin_reg.variables)\n",
    "    for g,v in zip(grads, lin_reg.variables):\n",
    "      v.assign_sub(learning_rate * g)\n",
    "    # Keep track of batch-level training performance \n",
    "    batch_losses_train.append(batch_loss)\n",
    "\n",
    "  # Iterate through the testing data\n",
    "  for x_batch, y_batch in test_dataset:\n",
    "    y_pred_batch = lin_reg(x_batch)\n",
    "    batch_loss = mse_loss(y_pred_batch, y_batch)\n",
    "    # Keep track of batch-level testing performance \n",
    "    batch_losses_test.append(batch_loss)\n",
    "\n",
    "  # Keep track of epoch-level model performance\n",
    "  train_loss = tf.reduce_mean(batch_losses_train)\n",
    "  test_loss = tf.reduce_mean(batch_losses_test)\n",
    "  train_losses.append(train_loss)\n",
    "  test_losses.append(test_loss)\n",
    "  if epoch % 10 == 0:\n",
    "    print(f'Mean squared error for step {epoch}: {train_loss.numpy():0.3f}')\n",
    "\n",
    "# Output final losses\n",
    "print(f\"\\nFinal train loss: {train_loss:0.3f}\")\n",
    "print(f\"Final test loss: {test_loss:0.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams['figure.figsize'] = [9, 6]\n",
    "\n",
    "plt.plot(range(epochs), train_losses, label = \"Training loss\")\n",
    "plt.plot(range(epochs), test_losses, label = \"Testing loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Mean squared error loss\")\n",
    "plt.legend()\n",
    "plt.title(\"MSE loss vs training iterations\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save and export model-  tf.saved_model.save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExportModule(tf.Module):\n",
    "  def __init__(self, model, extract_features, norm_x, norm_y):\n",
    "    # Initialize pre and postprocessing functions\n",
    "    self.model = model\n",
    "    self.extract_features = extract_features\n",
    "    self.norm_x = norm_x\n",
    "    self.norm_y = norm_y\n",
    "\n",
    "  @tf.function(input_signature=[tf.TensorSpec(shape=[None, None], dtype=tf.float32)]) \n",
    "  def __call__(self, x):\n",
    "    # Run the ExportModule for new data points\n",
    "    x = self.extract_features(x)\n",
    "    x = self.norm_x.norm(x)\n",
    "    y = self.model(x)\n",
    "    y = self.norm_y.unnorm(y)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg_export = ExportModule(model=lin_reg,\n",
    "                              extract_features=onehot_origin,\n",
    "                              norm_x=norm_x,\n",
    "                              norm_y=norm_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import os\n",
    "\n",
    "models = tempfile.mkdtemp()\n",
    "save_path = os.path.join(models, 'lin_reg_export')\n",
    "tf.saved_model.save(lin_reg_export, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg_loaded = tf.saved_model.load(save_path)\n",
    "test_preds = lin_reg_loaded(x_test)\n",
    "test_preds[:10].numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary classification using Keras and csv dataframe\n",
    "This tutorial provides examples of how to load pandas DataFrames into TensorFlow.\n",
    "\n",
    "You will use a small heart disease dataset provided by the UCI Machine Learning Repository. There are several hundred rows in the CSV. Each row describes a patient, and each column describes an attribute. You will use this information to predict whether a patient has heart disease, which is a binary classification task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load datasets and planning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = tf.keras.utils.get_file('heart.csv', 'https://storage.googleapis.com/download.tensorflow.org/data/heart.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.drop('thal', inplace= True, axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>fixed</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>160</td>\n",
       "      <td>286</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>normal</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>120</td>\n",
       "      <td>229</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>reversible</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   1       145   233    1        2      150      0      2.3      3   \n",
       "1   67    1   4       160   286    0        2      108      1      1.5      2   \n",
       "2   67    1   4       120   229    0        2      129      1      2.6      2   \n",
       "3   37    1   3       130   250    0        0      187      0      3.5      3   \n",
       "\n",
       "   ca        thal  target  \n",
       "0   0       fixed       0  \n",
       "1   3      normal       1  \n",
       "2   2  reversible       0  \n",
       "3   0      normal       0  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age           int64\n",
       "sex           int64\n",
       "cp            int64\n",
       "trestbps      int64\n",
       "chol          int64\n",
       "fbs           int64\n",
       "restecg       int64\n",
       "thalach       int64\n",
       "exang         int64\n",
       "oldpeak     float64\n",
       "slope         int64\n",
       "ca            int64\n",
       "thal         object\n",
       "target        int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df.pop('target')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data ingestion and preprocessing\n",
    "We will create he preprocessing into the model. While you could preprocess into dataframe using your familiar frameworks like Pandas and Polaris. It is best to build in model due to below reasons.\n",
    "Why Not Preprocess in the DataFrame?\n",
    "* Data Leakage: If you compute statistics (e.g., mean/std) on the entire dataset (instead of just the training split), you risk leaking information into validation/test data.\n",
    "\n",
    "* Deployment Complexity: You’d need to reapply the same pandas preprocessing steps every time you use the model, which is error-prone.\n",
    "\n",
    "* Scalability: Manual preprocessing doesn’t work for large datasets or streaming data.\n",
    "\n",
    "Best Practice\n",
    "Use Keras preprocessing layers or TensorFlow Transform (TFT) for:\n",
    "\n",
    "* Consistency: Preprocessing logic is baked into the model.\n",
    "\n",
    "* Portability: The saved model includes preprocessing, so no extra code is needed during deployment.\n",
    "\n",
    "* Adaptability: Preprocessors automatically handle new data with the same logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a list of columns falling onto each data type category\n",
    "binary_feature_names = ['sex', 'fbs', 'exang']\n",
    "categorical_feature_names = ['cp', 'restecg', 'slope', 'ca' \n",
    "                             , 'thal'\n",
    "                             ]\n",
    "numeric_feature_names = ['age', 'thalach', 'trestbps',  'chol', 'oldpeak']\n",
    "numeric_features = df[numeric_feature_names]\n",
    "# # Remaining will be numerical columns\n",
    "numeric_features_dict = {key: value.to_numpy()[:, tf.newaxis] for key, value in dict(numeric_features).items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras API\n",
    "This section uses the Keras Functional API to implement the preprocessing. You start by creating one tf.keras.Input for each column of the dataframe.\n",
    "For each input you'll apply some transformations using Keras layers and TensorFlow ops. Each feature starts as a batch of scalars (shape=(batch,)). The output for each should be a batch of tf.float32 vectors (shape=(batch, n)). The last step will concatenate all those vectors together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {}\n",
    "for name, column in df.items():\n",
    "  if type(column[0]) == str:\n",
    "    dtype = tf.string\n",
    "  elif (name in categorical_feature_names or\n",
    "        name in binary_feature_names):\n",
    "    dtype = tf.int64\n",
    "  else:\n",
    "    dtype = tf.float32\n",
    "\n",
    "  inputs[name] = tf.keras.Input(shape=(1,), name=name, dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'age': <KerasTensor shape=(None, 1), dtype=float32, sparse=False, name=age>,\n",
       " 'sex': <KerasTensor shape=(None, 1), dtype=int64, sparse=False, name=sex>,\n",
       " 'cp': <KerasTensor shape=(None, 1), dtype=int64, sparse=False, name=cp>,\n",
       " 'trestbps': <KerasTensor shape=(None, 1), dtype=float32, sparse=False, name=trestbps>,\n",
       " 'chol': <KerasTensor shape=(None, 1), dtype=float32, sparse=False, name=chol>,\n",
       " 'fbs': <KerasTensor shape=(None, 1), dtype=int64, sparse=False, name=fbs>,\n",
       " 'restecg': <KerasTensor shape=(None, 1), dtype=int64, sparse=False, name=restecg>,\n",
       " 'thalach': <KerasTensor shape=(None, 1), dtype=float32, sparse=False, name=thalach>,\n",
       " 'exang': <KerasTensor shape=(None, 1), dtype=int64, sparse=False, name=exang>,\n",
       " 'oldpeak': <KerasTensor shape=(None, 1), dtype=float32, sparse=False, name=oldpeak>,\n",
       " 'slope': <KerasTensor shape=(None, 1), dtype=int64, sparse=False, name=slope>,\n",
       " 'ca': <KerasTensor shape=(None, 1), dtype=int64, sparse=False, name=ca>,\n",
       " 'thal': <KerasTensor shape=(None, 1), dtype=string, sparse=False, name=thal>}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binary inputs\n",
    "Since the binary inputs don't need any preprocessing, just add the vector axis, cast them to float32 and add them to the list of preprocessed inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasTensor shape=(None, 1), dtype=int64, sparse=False, name=sex>,\n",
       " <KerasTensor shape=(None, 1), dtype=int64, sparse=False, name=fbs>,\n",
       " <KerasTensor shape=(None, 1), dtype=int64, sparse=False, name=exang>]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed = []\n",
    "\n",
    "for name in binary_feature_names:\n",
    "  inp = inputs[name]\n",
    "  preprocessed.append(inp)\n",
    "\n",
    "preprocessed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numeric inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = tf.keras.layers.Normalization(axis=-1)\n",
    "normalizer.adapt(np.concatenate([value for key, value in sorted(numeric_features_dict.items())], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasTensor shape=(None, 1), dtype=int64, sparse=False, name=sex>,\n",
       " <KerasTensor shape=(None, 1), dtype=int64, sparse=False, name=fbs>,\n",
       " <KerasTensor shape=(None, 1), dtype=int64, sparse=False, name=exang>,\n",
       " <KerasTensor shape=(None, 5), dtype=float32, sparse=False, name=keras_tensor_14>]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_inputs = []\n",
    "for name in numeric_feature_names:\n",
    "  numeric_inputs.append(inputs[name])\n",
    "\n",
    "numeric_inputs = tf.keras.layers.Concatenate(axis=-1)(numeric_inputs)\n",
    "numeric_normalized = normalizer(numeric_inputs)\n",
    "\n",
    "preprocessed.append(numeric_normalized)\n",
    "\n",
    "preprocessed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: cp\n",
      "vocab: [0, 1, 2, 3, 4]\n",
      "\n",
      "name: restecg\n",
      "vocab: [0, 1, 2]\n",
      "\n",
      "name: slope\n",
      "vocab: [1, 2, 3]\n",
      "\n",
      "name: ca\n",
      "vocab: [0, 1, 2, 3]\n",
      "\n",
      "name: thal\n",
      "vocab: ['1', '2', 'fixed', 'normal', 'reversible']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name in categorical_feature_names:\n",
    "  vocab = sorted(set(df[name]))\n",
    "  print(f'name: {name}')\n",
    "  print(f'vocab: {vocab}\\n')\n",
    "\n",
    "  if type(vocab[0]) is str:\n",
    "    lookup = tf.keras.layers.StringLookup(vocabulary=vocab, output_mode='one_hot')\n",
    "  else:\n",
    "    lookup = tf.keras.layers.IntegerLookup(vocabulary=vocab, output_mode='one_hot')\n",
    "\n",
    "  x = inputs[name]\n",
    "  x = lookup(x)\n",
    "  preprocessed.append(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assemble the preprocessing head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasTensor shape=(None, 1), dtype=int64, sparse=False, name=sex>,\n",
       " <KerasTensor shape=(None, 1), dtype=int64, sparse=False, name=fbs>,\n",
       " <KerasTensor shape=(None, 1), dtype=int64, sparse=False, name=exang>,\n",
       " <KerasTensor shape=(None, 5), dtype=float32, sparse=False, name=keras_tensor_14>,\n",
       " <KerasTensor shape=(None, 6), dtype=float32, sparse=False, name=keras_tensor_15>,\n",
       " <KerasTensor shape=(None, 4), dtype=float32, sparse=False, name=keras_tensor_16>,\n",
       " <KerasTensor shape=(None, 4), dtype=float32, sparse=False, name=keras_tensor_17>,\n",
       " <KerasTensor shape=(None, 5), dtype=float32, sparse=False, name=keras_tensor_18>,\n",
       " <KerasTensor shape=(None, 6), dtype=float32, sparse=False, name=keras_tensor_19>]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor shape=(None, 33), dtype=float32, sparse=False, name=keras_tensor_20>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_result = tf.keras.layers.Concatenate(axis=1)(preprocessed)\n",
    "preprocessed_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = tf.keras.Model(inputs, preprocessed_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install graphviz (see instructions at https://graphviz.gitlab.io/download/) for `plot_model` to work.\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(preprocessor, rankdir=\"LR\", show_shapes=True,  show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calling preprocess layer for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 33), dtype=float32, numpy=\n",
       "array([[  1.       ,   1.       ,   0.       ,   0.93384  ,  -1.8534899,\n",
       "        123.75735  ,   3.6224306,  -7.3077087,   0.       ,   0.       ,\n",
       "          1.       ,   0.       ,   0.       ,   0.       ,   0.       ,\n",
       "          0.       ,   0.       ,   1.       ,   0.       ,   0.       ,\n",
       "          0.       ,   1.       ,   0.       ,   1.       ,   0.       ,\n",
       "          0.       ,   0.       ,   0.       ,   0.       ,   0.       ,\n",
       "          1.       ,   0.       ,   0.       ]], dtype=float32)>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor(dict(df.iloc[:1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "body = tf.keras.Sequential([\n",
    "  tf.keras.layers.Dense(10, activation='relu'),\n",
    "  tf.keras.layers.Dense(10, activation='relu'),\n",
    "  tf.keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'age': <KerasTensor shape=(None, 1), dtype=float32, sparse=False, name=age>,\n",
       " 'sex': <KerasTensor shape=(None, 1), dtype=int64, sparse=False, name=sex>,\n",
       " 'cp': <KerasTensor shape=(None, 1), dtype=int64, sparse=False, name=cp>,\n",
       " 'trestbps': <KerasTensor shape=(None, 1), dtype=float32, sparse=False, name=trestbps>,\n",
       " 'chol': <KerasTensor shape=(None, 1), dtype=float32, sparse=False, name=chol>,\n",
       " 'fbs': <KerasTensor shape=(None, 1), dtype=int64, sparse=False, name=fbs>,\n",
       " 'restecg': <KerasTensor shape=(None, 1), dtype=int64, sparse=False, name=restecg>,\n",
       " 'thalach': <KerasTensor shape=(None, 1), dtype=float32, sparse=False, name=thalach>,\n",
       " 'exang': <KerasTensor shape=(None, 1), dtype=int64, sparse=False, name=exang>,\n",
       " 'oldpeak': <KerasTensor shape=(None, 1), dtype=float32, sparse=False, name=oldpeak>,\n",
       " 'slope': <KerasTensor shape=(None, 1), dtype=int64, sparse=False, name=slope>,\n",
       " 'ca': <KerasTensor shape=(None, 1), dtype=int64, sparse=False, name=ca>,\n",
       " 'thal': <KerasTensor shape=(None, 1), dtype=string, sparse=False, name=thal>}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor shape=(None, 33), dtype=float32, sparse=False, name=keras_tensor_21>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = preprocessor(inputs)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor shape=(None, 1), dtype=float32, sparse=False, name=keras_tensor_26>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = body(x)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Model(inputs, result)\n",
    "# To understand possible problem with contructor approach\n",
    "model.compile(optimizer='adam',\n",
    "                loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install graphviz (see instructions at https://graphviz.gitlab.io/download/) for `plot_model` to work.\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model, show_shapes=True,  show_layer_names=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHUFFLE_BUFFER = 500\n",
    "BATCH_SIZE = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'age': 0      63\n",
       " 1      67\n",
       " 2      67\n",
       " 3      37\n",
       " 4      41\n",
       "        ..\n",
       " 298    52\n",
       " 299    43\n",
       " 300    65\n",
       " 301    48\n",
       " 302    63\n",
       " Name: age, Length: 303, dtype: int64,\n",
       " 'sex': 0      1\n",
       " 1      1\n",
       " 2      1\n",
       " 3      1\n",
       " 4      0\n",
       "       ..\n",
       " 298    1\n",
       " 299    0\n",
       " 300    1\n",
       " 301    1\n",
       " 302    0\n",
       " Name: sex, Length: 303, dtype: int64,\n",
       " 'cp': 0      1\n",
       " 1      4\n",
       " 2      4\n",
       " 3      3\n",
       " 4      2\n",
       "       ..\n",
       " 298    1\n",
       " 299    4\n",
       " 300    4\n",
       " 301    4\n",
       " 302    4\n",
       " Name: cp, Length: 303, dtype: int64,\n",
       " 'trestbps': 0      145\n",
       " 1      160\n",
       " 2      120\n",
       " 3      130\n",
       " 4      130\n",
       "       ... \n",
       " 298    118\n",
       " 299    132\n",
       " 300    135\n",
       " 301    130\n",
       " 302    150\n",
       " Name: trestbps, Length: 303, dtype: int64,\n",
       " 'chol': 0      233\n",
       " 1      286\n",
       " 2      229\n",
       " 3      250\n",
       " 4      204\n",
       "       ... \n",
       " 298    186\n",
       " 299    341\n",
       " 300    254\n",
       " 301    256\n",
       " 302    407\n",
       " Name: chol, Length: 303, dtype: int64,\n",
       " 'fbs': 0      1\n",
       " 1      0\n",
       " 2      0\n",
       " 3      0\n",
       " 4      0\n",
       "       ..\n",
       " 298    0\n",
       " 299    1\n",
       " 300    0\n",
       " 301    1\n",
       " 302    0\n",
       " Name: fbs, Length: 303, dtype: int64,\n",
       " 'restecg': 0      2\n",
       " 1      2\n",
       " 2      2\n",
       " 3      0\n",
       " 4      2\n",
       "       ..\n",
       " 298    2\n",
       " 299    2\n",
       " 300    2\n",
       " 301    2\n",
       " 302    2\n",
       " Name: restecg, Length: 303, dtype: int64,\n",
       " 'thalach': 0      150\n",
       " 1      108\n",
       " 2      129\n",
       " 3      187\n",
       " 4      172\n",
       "       ... \n",
       " 298    190\n",
       " 299    136\n",
       " 300    127\n",
       " 301    150\n",
       " 302    154\n",
       " Name: thalach, Length: 303, dtype: int64,\n",
       " 'exang': 0      0\n",
       " 1      1\n",
       " 2      1\n",
       " 3      0\n",
       " 4      0\n",
       "       ..\n",
       " 298    0\n",
       " 299    1\n",
       " 300    0\n",
       " 301    1\n",
       " 302    0\n",
       " Name: exang, Length: 303, dtype: int64,\n",
       " 'oldpeak': 0      2.3\n",
       " 1      1.5\n",
       " 2      2.6\n",
       " 3      3.5\n",
       " 4      1.4\n",
       "       ... \n",
       " 298    0.0\n",
       " 299    3.0\n",
       " 300    2.8\n",
       " 301    0.0\n",
       " 302    4.0\n",
       " Name: oldpeak, Length: 303, dtype: float64,\n",
       " 'slope': 0      3\n",
       " 1      2\n",
       " 2      2\n",
       " 3      3\n",
       " 4      1\n",
       "       ..\n",
       " 298    2\n",
       " 299    2\n",
       " 300    2\n",
       " 301    1\n",
       " 302    2\n",
       " Name: slope, Length: 303, dtype: int64,\n",
       " 'ca': 0      0\n",
       " 1      3\n",
       " 2      2\n",
       " 3      0\n",
       " 4      0\n",
       "       ..\n",
       " 298    0\n",
       " 299    0\n",
       " 300    1\n",
       " 301    2\n",
       " 302    3\n",
       " Name: ca, Length: 303, dtype: int64,\n",
       " 'thal': 0           fixed\n",
       " 1          normal\n",
       " 2      reversible\n",
       " 3          normal\n",
       " 4          normal\n",
       "           ...    \n",
       " 298         fixed\n",
       " 299    reversible\n",
       " 300    reversible\n",
       " 301    reversible\n",
       " 302    reversible\n",
       " Name: thal, Length: 303, dtype: object}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid dtype: object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[64], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\optree\\ops.py:752\u001b[0m, in \u001b[0;36mtree_map\u001b[1;34m(func, tree, is_leaf, none_is_leaf, namespace, *rests)\u001b[0m\n\u001b[0;32m    750\u001b[0m leaves, treespec \u001b[38;5;241m=\u001b[39m _C\u001b[38;5;241m.\u001b[39mflatten(tree, is_leaf, none_is_leaf, namespace)\n\u001b[0;32m    751\u001b[0m flat_args \u001b[38;5;241m=\u001b[39m [leaves] \u001b[38;5;241m+\u001b[39m [treespec\u001b[38;5;241m.\u001b[39mflatten_up_to(r) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m rests]\n\u001b[1;32m--> 752\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtreespec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mflat_args\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid dtype: object"
     ]
    }
   ],
   "source": [
    "history = model.fit(dict(df), target, epochs=5, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using data pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(df),\n",
    "    target\n",
    "))\n",
    "\n",
    "ds = ds.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'age': <tf.Tensor: shape=(2,), dtype=int64, numpy=array([63, 67], dtype=int64)>,\n",
      " 'ca': <tf.Tensor: shape=(2,), dtype=int64, numpy=array([0, 3], dtype=int64)>,\n",
      " 'chol': <tf.Tensor: shape=(2,), dtype=int64, numpy=array([233, 286], dtype=int64)>,\n",
      " 'cp': <tf.Tensor: shape=(2,), dtype=int64, numpy=array([1, 4], dtype=int64)>,\n",
      " 'exang': <tf.Tensor: shape=(2,), dtype=int64, numpy=array([0, 1], dtype=int64)>,\n",
      " 'fbs': <tf.Tensor: shape=(2,), dtype=int64, numpy=array([1, 0], dtype=int64)>,\n",
      " 'oldpeak': <tf.Tensor: shape=(2,), dtype=float64, numpy=array([2.3, 1.5])>,\n",
      " 'restecg': <tf.Tensor: shape=(2,), dtype=int64, numpy=array([2, 2], dtype=int64)>,\n",
      " 'sex': <tf.Tensor: shape=(2,), dtype=int64, numpy=array([1, 1], dtype=int64)>,\n",
      " 'slope': <tf.Tensor: shape=(2,), dtype=int64, numpy=array([3, 2], dtype=int64)>,\n",
      " 'thal': <tf.Tensor: shape=(2,), dtype=string, numpy=array([b'fixed', b'normal'], dtype=object)>,\n",
      " 'thalach': <tf.Tensor: shape=(2,), dtype=int64, numpy=array([150, 108], dtype=int64)>,\n",
      " 'trestbps': <tf.Tensor: shape=(2,), dtype=int64, numpy=array([145, 160], dtype=int64)>}\n",
      "\n",
      "tf.Tensor([0 1], shape=(2,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "for x, y in ds.take(1):\n",
    "  pprint.pprint(x)\n",
    "  print()\n",
    "  print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7503 - loss: 0.6387\n",
      "Epoch 2/5\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6991 - loss: 0.6270\n",
      "Epoch 3/5\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7390 - loss: 0.5598\n",
      "Epoch 4/5\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7545 - loss: 0.5055\n",
      "Epoch 5/5\n",
      "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7496 - loss: 0.4606\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(ds, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
